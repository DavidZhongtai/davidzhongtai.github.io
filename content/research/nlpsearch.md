## Building an NLP-Powered Repository for Cyber Risk Literature [[Poster]](/research/draft1.pdf)
David An, Linfeng Zheng, Zhiqu (Frank) Quan
### Abstract
With the large and growing body of cyber risk literature, we see three major challenges faced by the actuarial research community: there is no context aware tool for finding cyber literature, no central repository of cyber risk resources, and a lack of accounting of literature trends. To address the abovementioned challenges, we propose to build a repository of cyber-risk articles with an NLP powered search tool that can easily be used by researchers to find relevant materials. We cover a high level overview of this ongoing research project

### Goals
- Apply natural language processing (NLP) techniques to classify and group cyber-risk and cybersecurity related academic literature. Using this information, we want to construct a tool for academics and researchers to use to identify trends and new technologies in cyber-risk and cyber security.

- For example, given a text query, a researcher would be able to obtain relevant pieces of literature and topics to use as well as visualize trends and different topic groupings.

- In addition to that, researchers would be able to suggest and add new pieces of literature into the database as well. This would become a growing repository that will continuously update with time.

### Takeaways
In the real world, data is never clean. The ideal is perfectly shaped data, the dimensions adjusted to our specification, and no missing values. However, reality is far from ideal. Data goes missing in transmission, findings don't turn out quite right, and sometimes, data just forgets to get recorded. When these accumulate, we end up with a variety of problems such as inbalanced data, missing critical values, or values that aren't representative of our actual situation. For us, we had everything from missing titles and abstracts to lists of keywords. In some cases, such as keywords, we are able to perform different methods to extract keywords. However, for larger data fields where high precision is needed (i.e. abstracts and titles), these entries would need to be deleted. These problems show the need for a unifying system for academic literature. 

Semantic representation is hard. Really hard. Being able to represent 'meaning' in a way that computers can understand still remains a challenge to cutting edge researchers to this day. The challenge for us was being able to generate a semantic representation of various keyword phrases accurately. 
